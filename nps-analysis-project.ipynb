{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nicholastadeu/nps-analysis-project?scriptVersionId=144611468\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"#importing libraries\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.31954Z","iopub.execute_input":"2023-09-28T23:01:21.319898Z","iopub.status.idle":"2023-09-28T23:01:21.325148Z","shell.execute_reply.started":"2023-09-28T23:01:21.319868Z","shell.execute_reply":"2023-09-28T23:01:21.323472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading the csv file as a pandas dataframe\nnps_data = pd.read_csv('/kaggle/input/npsbank/NPStimeseries.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.334591Z","iopub.execute_input":"2023-09-28T23:01:21.335065Z","iopub.status.idle":"2023-09-28T23:01:21.346722Z","shell.execute_reply.started":"2023-09-28T23:01:21.335039Z","shell.execute_reply":"2023-09-28T23:01:21.345958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#analizyng the df head\n\nnps_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.350483Z","iopub.execute_input":"2023-09-28T23:01:21.350905Z","iopub.status.idle":"2023-09-28T23:01:21.359637Z","shell.execute_reply.started":"2023-09-28T23:01:21.350883Z","shell.execute_reply":"2023-09-28T23:01:21.358592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#analizyng each collum\n\nnps_data.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.368099Z","iopub.execute_input":"2023-09-28T23:01:21.368498Z","iopub.status.idle":"2023-09-28T23:01:21.380168Z","shell.execute_reply.started":"2023-09-28T23:01:21.368468Z","shell.execute_reply":"2023-09-28T23:01:21.379006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#analizyng the shape\n\nnps_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.381807Z","iopub.execute_input":"2023-09-28T23:01:21.382722Z","iopub.status.idle":"2023-09-28T23:01:21.395794Z","shell.execute_reply.started":"2023-09-28T23:01:21.382692Z","shell.execute_reply":"2023-09-28T23:01:21.394786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing the df\n\nnps_data","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.397252Z","iopub.execute_input":"2023-09-28T23:01:21.397904Z","iopub.status.idle":"2023-09-28T23:01:21.412438Z","shell.execute_reply.started":"2023-09-28T23:01:21.397879Z","shell.execute_reply":"2023-09-28T23:01:21.411844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# counting the unique values in the clients column and showing the max and minimum times that one customer reponded the survey\nnps_data['Customer Name'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.413584Z","iopub.execute_input":"2023-09-28T23:01:21.414593Z","iopub.status.idle":"2023-09-28T23:01:21.427123Z","shell.execute_reply.started":"2023-09-28T23:01:21.41457Z","shell.execute_reply":"2023-09-28T23:01:21.4262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#counting the unique values in the NPS Score column and showing the max and minimum times that the score was choosed\nnps_data['NPS'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.428362Z","iopub.execute_input":"2023-09-28T23:01:21.428856Z","iopub.status.idle":"2023-09-28T23:01:21.436801Z","shell.execute_reply.started":"2023-09-28T23:01:21.428835Z","shell.execute_reply":"2023-09-28T23:01:21.434913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# specifying the column names that I want to use\n\nnew_cols_dict ={\n    'Survey date':'Date',\n    'Customer Name':'Name',\n    'NPS':'Score'\n}\n        \n#renaming the columns to the specified column names\nnps_data.rename(new_cols_dict, axis=1, inplace=True)\n\nnps_data","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.468772Z","iopub.execute_input":"2023-09-28T23:01:21.469112Z","iopub.status.idle":"2023-09-28T23:01:21.483578Z","shell.execute_reply.started":"2023-09-28T23:01:21.469085Z","shell.execute_reply":"2023-09-28T23:01:21.482708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a new collumn with the NPS profile of each client, to facilitate calculating NPS\ndef define_profile(score):\n    if score <= 6:\n        return 'Detractor'\n    elif score <= 8:\n        return 'Passive'\n    else:\n        return 'Promoter'\n\n#apllying the function to create the new \"Profile\" column\nnps_data['Profile'] = nps_data['Score'].apply(define_profile)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.485052Z","iopub.execute_input":"2023-09-28T23:01:21.485289Z","iopub.status.idle":"2023-09-28T23:01:21.495204Z","shell.execute_reply.started":"2023-09-28T23:01:21.485268Z","shell.execute_reply":"2023-09-28T23:01:21.49432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#making sure that the changes are effective\n\nnps_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.500916Z","iopub.execute_input":"2023-09-28T23:01:21.501333Z","iopub.status.idle":"2023-09-28T23:01:21.512384Z","shell.execute_reply.started":"2023-09-28T23:01:21.501303Z","shell.execute_reply":"2023-09-28T23:01:21.511738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ploting a graphic with the % of each nps profile per market\n\n#calculating the % of each profile by market\nprofile_percentage = nps_data.groupby(['Market', 'Profile']).size() / nps_data.groupby('Market').size() * 100\nprofile_percentage = profile_percentage.unstack().fillna(0)\n\n#defining colors for profiles\ncolors = {'Promoter': 'green', 'Passive': 'sandybrown', 'Detractor': 'red'}\n\n#ploting the stacked bar chart\nax = profile_percentage.plot(kind='bar', stacked=True, color=[colors[col] for col in profile_percentage.columns])\n\nplt.xlabel('Market')\nplt.ylabel('Percentage')\nplt.title('Percentage of Profiles by Market')\n\n#displaying legend with custom labels\nhandles, labels = ax.get_legend_handles_labels()\nax.legend(handles=[plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels], labels=labels)\n\n#adding labels with percentage values on top of the bars\nfor container in ax.containers:\n    ax.bar_label(container, fmt='%.2f%%', label_type='center', fontsize=10, color='white')\n    \nplt.ylim(0, 150)\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.516143Z","iopub.execute_input":"2023-09-28T23:01:21.516619Z","iopub.status.idle":"2023-09-28T23:01:21.743512Z","shell.execute_reply.started":"2023-09-28T23:01:21.516589Z","shell.execute_reply":"2023-09-28T23:01:21.742468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plting a graphic to see how many responses each market has\n\n#group by Market and count the responses\nresponses_count = nps_data.groupby('Market')['Score'].count()\n\n\n#ploting a bar chart\nax = responses_count.plot(kind='bar', color='blue', edgecolor='black')\n\n#adding labels with the number of responses above each bar\nfor i, v in enumerate(responses_count):\n    ax.text(i, v + 1, str(v), ha='center', va='bottom', fontsize=12)\n    \nplt.ylim(0, 2000)\n\n\n#setting labels, title, and legend\nplt.xlabel('Market')\nplt.ylabel('Number of Responses')\nplt.title('Number of Responses by Market')\nplt.legend(['Responses'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.745145Z","iopub.execute_input":"2023-09-28T23:01:21.745385Z","iopub.status.idle":"2023-09-28T23:01:21.9498Z","shell.execute_reply.started":"2023-09-28T23:01:21.745365Z","shell.execute_reply":"2023-09-28T23:01:21.949109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#answering the first big question, \"what is the NPS Score of my base?\"\n\n#calculating the total count of Promoters, Neutrals, and Detractors\ntotal_count = len(nps_data)\npromoter_count = (nps_data['Profile'] == 'Promoter').sum()\npassive_count = (nps_data['Profile'] == 'Passive').sum()\ndetractor_count = (nps_data['Profile'] == 'Detractor').sum()\n\npromoter_porcentage = promoter_count / total_count * 100\npassive_porcentage = passive_count / total_count * 100\ndetractor_porcentage = detractor_count / total_count * 100\n\n#calculating the overall NPS (Promoters - Detractors) for the entire DataFrame\noverall_nps = (promoter_count - detractor_count) / total_count * 100\n\n#printing the percentage and the final grade results. I'm printing the percentages too as a prove that the final grade is correct\nprint(f\" Promoters: {promoter_porcentage:.2f}\")\nprint(f\" Passives: {passive_porcentage:.2f}\")\nprint(f\" Detractors: {detractor_porcentage:.2f}\")\n\nprint(f\" NPS Score: {overall_nps:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.951105Z","iopub.execute_input":"2023-09-28T23:01:21.951826Z","iopub.status.idle":"2023-09-28T23:01:21.959843Z","shell.execute_reply.started":"2023-09-28T23:01:21.951796Z","shell.execute_reply":"2023-09-28T23:01:21.95922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#aswering the secund big question, \"Witch Market has the best NPS?\" by calculating NPS per market\n\n#calulating the total os responses per market\nmarket_counts = nps_data['Market'].value_counts()\n\n#counting promoters and detractors by market\npromoter_counts = nps_data[nps_data['Profile'] == 'Promoter']['Market'].value_counts()\ndetractor_counts = nps_data[nps_data['Profile'] == 'Detractor']['Market'].value_counts()\n\n#calculating the % of promoters and detractors per market\npercentage_promoters = (promoter_counts / market_counts) * 100\npercentage_detectors = (detractor_counts / market_counts) * 100\n\n#calculating the NPS (% of Promoters - % of Detractors) per market\nnps_by_market = percentage_promoters - percentage_detectors\n\n#creating a new df to put the results\nnps_result_by_market = pd.DataFrame({'Market': nps_by_market.index, 'NPS': nps_by_market.values})\n\n#printing the result\nnps_result_by_market","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.96146Z","iopub.execute_input":"2023-09-28T23:01:21.962171Z","iopub.status.idle":"2023-09-28T23:01:21.985546Z","shell.execute_reply.started":"2023-09-28T23:01:21.962149Z","shell.execute_reply":"2023-09-28T23:01:21.98435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking if the original df wasn't affected\nnps_data","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:21.986719Z","iopub.execute_input":"2023-09-28T23:01:21.98699Z","iopub.status.idle":"2023-09-28T23:01:22.005304Z","shell.execute_reply.started":"2023-09-28T23:01:21.986968Z","shell.execute_reply":"2023-09-28T23:01:22.004423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calculating NPS per day, this will help to validate the data on tableau afterwards\n\n#creating a function to calculate the nps\ndef calculate_nps(group):\n    promoters = (group['Profile'] == 'Promoter').sum()\n    detractors = (group['Profile'] == 'Detractor').sum()\n    total = len(group)\n    return ((promoters - detractors) / total) * 100\n\n#grouping all the responses per date in a new df\nnps_by_date = nps_data.groupby('Date').apply(calculate_nps).reset_index(name='NPS')\n\n# Exiba o resultado\nprint(nps_by_date)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:22.006502Z","iopub.execute_input":"2023-09-28T23:01:22.006825Z","iopub.status.idle":"2023-09-28T23:01:22.159724Z","shell.execute_reply.started":"2023-09-28T23:01:22.006797Z","shell.execute_reply":"2023-09-28T23:01:22.158143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#choosing a name for the archive\noutput_excel_file = 'nps_analisys.xlsx'\n\n#exporting the df to an excel file\nnps_data.to_excel(output_excel_file, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:22.162497Z","iopub.execute_input":"2023-09-28T23:01:22.162765Z","iopub.status.idle":"2023-09-28T23:01:22.909581Z","shell.execute_reply.started":"2023-09-28T23:01:22.162743Z","shell.execute_reply":"2023-09-28T23:01:22.908443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Now that we have our data for tableu, i'll star a process more focused on data science in our df**","metadata":{}},{"cell_type":"code","source":"#making sure that the column Date is actually datetime\nnps_data['Date'] = pd.to_datetime(nps_data['Date'], format='%d/%m/%Y')\n\n#creating a new df with only the columns I will use\nnps_asis = nps_data[['Date', 'Score', 'Profile']].copy()\n\n#adding a new column, with the week day of the date\nnps_asis['Day_of_Week'] = nps_data['Date'].dt.day_name()\n\n#seeing the new df\nnps_asis","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:22.912952Z","iopub.execute_input":"2023-09-28T23:01:22.913265Z","iopub.status.idle":"2023-09-28T23:01:22.935131Z","shell.execute_reply.started":"2023-09-28T23:01:22.913237Z","shell.execute_reply":"2023-09-28T23:01:22.934289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#counting the answers per week day\ncount_by_day_of_week = nps_asis['Day_of_Week'].value_counts().reset_index()\n\n#renaming the columns\ncount_by_day_of_week.columns = ['Day_of_Week', 'Count']\n\ncount_by_day_of_week = count_by_day_of_week.sort_values(by='Count', ascending=False)\n\n\n#seeing the result\nprint(count_by_day_of_week)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:22.937022Z","iopub.execute_input":"2023-09-28T23:01:22.937258Z","iopub.status.idle":"2023-09-28T23:01:22.94601Z","shell.execute_reply.started":"2023-09-28T23:01:22.937239Z","shell.execute_reply":"2023-09-28T23:01:22.944922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a function to calculate the nps\ndef calculate_nps(group):\n    promoters = (group['Profile'] == 'Promoter').sum()\n    detractors = (group['Profile'] == 'Detractor').sum()\n    total = len(group)\n    nps = ((promoters - detractors) / total) * 100\n    return round(nps, 2) \n\n#grouping by Day of week and calculating the nps\nnps_by_day_of_week = nps_asis.groupby('Day_of_Week').apply(calculate_nps).reset_index(name='NPS')\n\n#ordering from biggest to smallest\nnps_by_day_of_week = nps_by_day_of_week.sort_values(by='NPS', ascending=False)\n\n#seeing the result\nnps_by_day_of_week\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:22.948699Z","iopub.execute_input":"2023-09-28T23:01:22.948933Z","iopub.status.idle":"2023-09-28T23:01:22.971026Z","shell.execute_reply.started":"2023-09-28T23:01:22.948913Z","shell.execute_reply":"2023-09-28T23:01:22.970324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\n\n#creating a crosstab between Score and Profile\ncontingency_table = pd.crosstab(nps_asis['Score'], nps_asis['Profile'])\n\n#doing the test\nchi2, p, _, _ = chi2_contingency(contingency_table)\n\n#showing the p-value\nprint(f\"P-Value: {p}\")\n\n#analyzing the result\nalpha = 0.05 \nif p <= alpha:\n    print(\"There is a correlation between Score and Profile\")\nelse:\n    print(\"The correlation doesen't exists\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:22.972054Z","iopub.execute_input":"2023-09-28T23:01:22.972319Z","iopub.status.idle":"2023-09-28T23:01:22.989289Z","shell.execute_reply.started":"2023-09-28T23:01:22.972297Z","shell.execute_reply":"2023-09-28T23:01:22.987958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\n\n#creating a column Days_Since_Start that represents the counting of days starting at a refer date\nnps_asis['Date'] = pd.to_datetime(nps_asis['Date'])  \nstart_date = min(nps_asis['Date']) \nnps_asis['Days_Since_Start'] = (nps_asis['Date'] - start_date).dt.days\n\n#adding a constant for the regression\nnps_asis['const'] = 1\n\n#defining a independent and dependent variables\nX = nps_asis[['const', 'Days_Since_Start']]\ny = nps_asis['Score']\n\n#running the model\nmodel = sm.OLS(y, X).fit()\n\n#analyzing the result\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:22.9905Z","iopub.execute_input":"2023-09-28T23:01:22.990738Z","iopub.status.idle":"2023-09-28T23:01:23.039587Z","shell.execute_reply.started":"2023-09-28T23:01:22.990717Z","shell.execute_reply":"2023-09-28T23:01:23.038585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In general, the regression results indicate that the variable **'Days_Since_Start'** is not significantly related to customer scores. **The low R-squared** suggests that other factors not included in the model may play a more significant role in explaining variations in customer scores.\n\nTherefore, let's now focus more on the days of the week rather than the open date.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\n\n#creating a new df for the analysis\nanalysis_df = nps_asis[['Day_of_Week', 'Score']]\n\n#performing an Analysis of Variance (ANOVA)\nmodel = ols('Score ~ Day_of_Week', data=analysis_df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\n\n#analyzing the result\nprint(anova_table)\n#if the p-value (PR(>F)) is less than a chosen significance level (e.g. 0.05), you can conclude that there is a significant correlation between 'Day_of_Week' and 'Score'.","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:23.040828Z","iopub.execute_input":"2023-09-28T23:01:23.041164Z","iopub.status.idle":"2023-09-28T23:01:23.08219Z","shell.execute_reply.started":"2023-09-28T23:01:23.041136Z","shell.execute_reply":"2023-09-28T23:01:23.081338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the analysis of variance, there does not appear to be a significant correlation between the day of the week (column 'Day_of_Week') and the scores (column 'Score'). Therefore, there is no statistical evidence to claim that the days of the week have a significant impact on customer scores based on the analyzed data.","metadata":{}},{"cell_type":"markdown","source":"# Now, I will respond the last big question \"The clients that responded more than one time, the perception of value improved or not?\"","metadata":{}},{"cell_type":"code","source":"#selecting only the occurrences of \"Name\" that are duplicated\nrepeated_names = nps_data[nps_data['Name'].duplicated(keep=False)]\n\n#creating a new DataFrame with the duplicated occurrences\nnps_timeline = pd.DataFrame(repeated_names)\n\n#reseting the index of the new DataFrame, if necessary\nnps_timeline.reset_index(drop=True, inplace=True)\n\n#analysing the result\nnps_timeline\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:23.083271Z","iopub.execute_input":"2023-09-28T23:01:23.084322Z","iopub.status.idle":"2023-09-28T23:01:23.102042Z","shell.execute_reply.started":"2023-09-28T23:01:23.084292Z","shell.execute_reply":"2023-09-28T23:01:23.101353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#making sure that there are only duplicates\nnps_timeline['Name'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:23.103012Z","iopub.execute_input":"2023-09-28T23:01:23.10389Z","iopub.status.idle":"2023-09-28T23:01:23.111618Z","shell.execute_reply.started":"2023-09-28T23:01:23.103862Z","shell.execute_reply":"2023-09-28T23:01:23.110716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#sorting the DataFrame by 'Name' and 'Date'\nnps_timeline.sort_values(by=['Name', 'Date'], inplace=True)\n\n#creating a new DataFrame to store the timeline\ntimeline_df = pd.DataFrame(columns=['Name', 'Profile_From', 'Profile_To', 'Date_From', 'Date_To'])\n\n#initialyzing variables to track the profile transitions\ncurrent_name = None\nprofile_from = None\ndate_from = None\n\n#iterating through the sorted DataFrame\nfor index, row in nps_timeline.iterrows():\n    if current_name is None:\n        current_name = row['Name']\n        profile_from = row['Profile']\n        date_from = row['Date']\n    elif current_name == row['Name']:\n        if profile_from != row['Profile']:\n            # Profile transition detected, record the change in the timeline DataFrame\n            timeline_df = pd.concat([timeline_df, pd.DataFrame({'Name': [current_name],\n                                                                'Profile_From': [profile_from],\n                                                                'Profile_To': [row['Profile']],\n                                                                'Date_From': [date_from],\n                                                                'Date_To': [row['Date']]})], ignore_index=True)\n            profile_from = row['Profile']\n            date_from = row['Date']\n    else:\n        current_name = row['Name']\n        profile_from = row['Profile']\n        date_from = row['Date']\n\n#cheking if the last profile transition is missing and add it to the timeline\nif current_name is not None:\n    timeline_df = pd.concat([timeline_df, pd.DataFrame({'Name': [current_name],\n                                                        'Profile_From': [profile_from],\n                                                        'Profile_To': [profile_from],  # Use the last profile as 'Profile_To'\n                                                        'Date_From': [date_from],\n                                                        'Date_To': [nps_timeline['Date'].max()]})], ignore_index=True)\n\n#analysing the result\ntimeline_df","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:23.112755Z","iopub.execute_input":"2023-09-28T23:01:23.113509Z","iopub.status.idle":"2023-09-28T23:01:23.26343Z","shell.execute_reply.started":"2023-09-28T23:01:23.113478Z","shell.execute_reply":"2023-09-28T23:01:23.262561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#counting occurrences of transitions from Detractor to Promoter\ndet_to_prom_count = (timeline_df[(timeline_df['Profile_From'] == 'Detractor') & (timeline_df['Profile_To'] == 'Promoter')]\n                     .shape[0])\n\n#counting occurrences of transitions from Promoter to Detractor\nprom_to_det_count = (timeline_df[(timeline_df['Profile_From'] == 'Promoter') & (timeline_df['Profile_To'] == 'Detractor')]\n                     .shape[0])\n\n#counting occurrences of transitions from Neutrals to Promoters\nneu_to_prom_count = (timeline_df[(timeline_df['Profile_From'] == 'Passive') & (timeline_df['Profile_To'] == 'Promoter')]\n                     .shape[0])\n\n#counting occurrences of transitions from Neutrals to Detractors\nneu_to_det_count = (timeline_df[(timeline_df['Profile_From'] == 'Passive') & (timeline_df['Profile_To'] == 'Detractor')]\n                     .shape[0])\n\nprint(\"Occurrences of transitions:\")\nprint(\"Detractor to Promoter:\", det_to_prom_count)\nprint(\"Promoter to Detractor:\", prom_to_det_count)\nprint(\"Passive to Promoters:\", neu_to_prom_count)\nprint(\"Passive to Detractors:\", neu_to_det_count)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:01:23.264496Z","iopub.execute_input":"2023-09-28T23:01:23.265636Z","iopub.status.idle":"2023-09-28T23:01:23.276433Z","shell.execute_reply.started":"2023-09-28T23:01:23.265606Z","shell.execute_reply":"2023-09-28T23:01:23.275463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Overall, these transitions highlight the dynamic nature of customer sentiment and the potential for both positive and negative shifts in customer perception over time. It's essential for businesses to monitor and understand these transitions to improve customer satisfaction and loyalty.","metadata":{}}]}